# 理解线程与线程池

[深入计算机底层，理解线程与线程池](http://www.52im.net/thread-3272-1-1.html)

CPU并不知道线程、进程之类的概念

**CPU只知道两件事：**

- 1）从内存中取出指令；
- 2）执行指令，然后回到 1）

CPU从哪里取出指令呢？答案是来自一个被称为Program Counter（简称PC）的寄存器，也就是我们熟知的[程序计数器](https://www.zhihu.com/search?q=程序计数器&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A339016204})

PC寄存器中存放的是什么呢？这里存放的是指令在内存中的地址，什么指令呢？是CPU将要执行的下一条指令

那么是谁来设置PC寄存器中的指令地址呢？

原来PC寄存器中的地址默认是自动加1的，这当然是有道理的，因为大部分情况下CPU都是一条接一条顺序执行，当遇到if、else时，这种顺序执行就被打破了，CPU在执行这类指令时会根据计算结果来动态改变PC寄存器中的值，这样CPU就可以正确的跳转到需要执行的指令了

我们想要CPU执行一个函数，那么只需要把该函数对应的第一条机器指令的地址写入PC寄存器就可以了，这样我们写的函数就开始被CPU执行起来啦

## 从CPU到操作系统

**我们需要：**

- 1）在内存中找到一块大小合适的区域装入程序；
- 2）找到函数入口，设置好PC寄存器让CPU开始执行程序

进程（Process）诞生了

## 从单核到多核，如何充分利用多核

假设我们想写一个程序并且要分利用多核该怎么办呢？

有的同学可能会说不是有进程吗，多开几个进程不就可以了？

**听上去似乎很有道理，但是主要存在这样几个问题：**

- 1）进程是需要占用内存空间的(从上一节能看到这一点)，如果多个进程基于同一个可执行程序，那么这些进程其内存区域中的内容几乎完全相同，这显然会造成内存的浪费；
- 2）计算机处理的任务可能是比较复杂的，这就涉及到了[进程间通信](https://www.zhihu.com/search?q=进程间通信&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A339016204})，由于各个进程处于不同的内存地址空间，进程间通信天然需要借助操作系统，这就在增大编程难度的同时也增加了系统开销

## 从进程到线程

所谓进程无非就是内存中的一段区域，这段区域中保存了CPU执行的机器指令以及函数运行时的堆栈信息，要想让进程运行，就把main函数的第一条机器指令地址写入PC寄存器，这样进程就运行起来了

进程的缺点在于只有一个入口函数，也就是main函数，因此进程中的机器指令只能被一个CPU执行，那么有没有办法让多个CPU来执行同一个进程中的机器指令呢？

聪明的你应该能想到，既然我们可以把main函数的第一条指令地址写入PC寄存器，那么其它函数和main函数又有什么区别呢？

答案是没什么区别，main函数的特殊之处无非就在于是CPU执行的第一个函数，除此之外再无特别之处，我们可以把PC寄存器指向main函数，就可以把PC寄存器指向任何一个函数。

当我们把PC寄存器指向非main函数时，线程就诞生了

由于各个线程共享进程的[内存地址空间](https://www.zhihu.com/search?q=内存地址空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A339016204})，因此线程之间的通信无需借助操作系统，这给程序员带来极大方便的同时也带来了无尽的麻烦，多线程遇到的多数问题都出自于线程间通信简直太方便了以至于非常容易出错。出错的根源在于CPU执行指令时根本没有线程的概念，多线程编程面临的互斥与同步问题需要程序员自己解决

不是说一定要有多核才能使用多线程，在单核的情况下一样可以创建出多个线程，原因在于线程是操作系统层面的实现，和有多少个核心是没有关系的，CPU在执行机器指令时也意识不到执行的机器指令属于哪个线程。即使在只有一个CPU的情况下，操作系统也可以通过线程调度让各个线程“同时”向前推进，方法就是将CPU的时间片在各个线程之间来回分配，这样多个线程看起来就是“同时”运行了，但实际上任意时刻还是只有一个线程在运行

## 线程与内存

函数在被执行的时产生的数据包括：函数参数、[局部变量](https://www.zhihu.com/search?q=局部变量&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"article"%2C"sourceId"%3A339016204})、返回地址等信息。这些信息是保存在栈中的，线程这个概念还没有出现时进程中只有一个执行流，因此只有一个栈，这个栈的栈底就是进程的入口函数，也就是main函数

有了线程以后一个进程中就存在多个执行入口，即同时存在多个执行流，那么只有一个执行流的进程需要一个栈来保存运行时信息，那么很显然有多个执行流时就需要有多个栈来保存各个执行流的信息，也就是说操作系统要为每个线程在进程的地址空间中分配一个栈，即每个线程都有独属于自己的栈

## 从多线程到线程池

线程池的概念是非常简单的，无非就是创建一批线程，之后就不再释放了，有任务就提交给这些线程处理，因此无需频繁的创建、销毁线程，同时由于线程池中的线程个数通常是固定的，也不会消耗过多的内存，因此这里的思想就是复用、可控

## 线程池是如何工作的

可能有的同学会问，该怎么给线程池提交任务呢？这些任务又是怎么给到线程池中线程呢？

很显然，数据结构中的队列天然适合这种场景，提交任务的就是生产者，消费任务的线程就是消费者

# 理解I/O与零拷贝技术

[从根上理解高性能、高并发(二)：深入操作系统，理解I/O与零拷贝技术](http://www.52im.net/thread-3280-1-1.html)

操作系统检测到进程A向I/O设备发起请求后就暂停进程的运行，怎么暂停运行呢？很简单：只需要记录下当前进程的运行状态并把CPU的PC寄存器指向其它进程的指令就可以了。

进程有暂停就会有继续执行，因此操作系统必须保存被暂停的进程以备后续继续执行，显然我们可以用队列来保存被暂停执行的进程

操作系统中除了有阻塞队列之外也有就绪队列，所谓就绪队列是指队列里的进程准备就绪可以被CPU执行了

此后磁盘终于将全部数据都copy到了进程A的内存中，这时磁盘通知操作系统任务完成啦，你可能会问怎么通知呢？这就是中断。

操作系统接收到磁盘中断后发现数据copy完毕，进程A重新获得继续运行的资格，这时操作系统小心翼翼的把进程A从阻塞队列放到了就绪队列当中

# 彻底理解I/O多路复用

## 什么是文件？

实际上所有的I/O设备都被抽象为了文件这个概念，一切皆文件（Everything is File），磁盘、网络数据、终端，甚至进程间通信工具管道pipe等都被当做文件对待

所有的I/O操作也都可以通过文件读写来实现，这一非常优雅的抽象可以让程序员使用一套接口就能对所有外设I/O操作

**常用的I/O操作接口一般有以下几类：**

- 1）打开文件，open；
- 2）改变读写位置，seek；
- 3）文件读写，read、write；
- 4）关闭文件，close。


程序员通过这几个接口几乎可以实现所有I/O操作，这就是文件这个概念的强大之处

## 什么是文件描述符？

文件描述仅仅就是一个数字而已，但是通过这个数字我们可以操作一个打开的文件

有了文件描述符，进程可以对文件一无所知，比如文件在磁盘的什么位置、加载到内存中又是怎样管理的等等，这些信息统统交由操作系统打理，进程无需关心，操作系统只需要给进程一个文件描述符就足够了

## 文件描述符太多了怎么办？

**这里的关键点在于：**我们事先并不知道一个文件描述对应的I/O设备是否是可读的、是否是可写的，在外设的不可读或不可写的状态下进行I/O只会导致进程阻塞被暂停运行

## I/O多路复用（I/O multiplexing）

**所谓I/O多路复用指的是这样一个过程：**

- 1）我们拿到了一堆文件描述符（不管是网络相关的、还是磁盘文件相关等等，任何文件描述符都可以）；
- 2）通过调用某个函数告诉内核：“这个函数你先不要返回，你替我监视着这些描述符，当这堆文件描述符中有可以进行I/O读写操作的时候你再返回”；
- 3）当调用的这个函数返回后我们就能知道哪些文件描述符可以进行I/O操作了。

# 理解高并发中的协程

## 函数只是协程的一种特例

协程会在函数被暂停运行时保存函数的运行状态，并可以从保存的状态中恢复并继续运行。

很熟悉的味道有没有，这不就是操作系统对线程的调度嘛，线程也可以被暂停，操作系统保存线程运行状态然后去调度其它线程，此后该线程再次被分配CPU时还可以继续运行，就像没有被暂停过一样。

只不过线程的调度是操作系统实现的，这些对程序员都不可见，而协程是在用户态实现的，对程序员可见。

这就是为什么有的人说可以把协程理解为用户态线程的原因

现在你应该理解为什么说函数只是协程的一种特例了吧，函数其实只是没有挂起点的协程而已

## 协程到底是如何实现的？

协程之所以可以被暂停也可以继续，那么一定要记录下被暂停时的状态，也就是上下文，当继续运行的时候要恢复其上下文（状态）**另外：**函数运行时所有的状态信息都位于函数运行时栈中。

函数运行时栈就是我们需要保存的状态，也就是所谓的上下文

**实际上：**我们需要做的是直接把协程的运行需要的栈帧空间直接开辟在堆区中

使用协程理论上我们可以开启无数并发执行流，只要堆区空间足够，同时还没有创建线程的开销，所有协程的调度、切换都发生在用户态，这就是为什么协程也被称作用户态线程的原因所在

即使你创建了N多协程，但在操作系统看来依然只有一个线程，也就是说协程对操作系统来说是不可见的

## 协程技术概念小结

### 协程是比线程更小的执行单元

协程是比线程更小的一种执行单元，你可以认为是轻量级的线程。

**之所以说轻：**其中一方面的原因是协程所持有的栈比线程要小很多，java当中会为每个线程分配1M左右的栈空间，而协程可能只有几十或者几百K，栈主要用来保存函数参数、局部变量和返回地址等信息

由于线程是操作系统的最小执行单元，因此也可以得出，协程是基于线程实现的，协程的创建、切换、销毁都是在某个线程中来进行的。

使用协程是因为线程的切换成本比较高，而协程在这方面很有优势

# 高性能服务器到底是如何实现的

## 事件驱动：Event Loop

**这一技术需要两种原料：**

- 1）event；
- 2）处理event的函数，这一函数通常被称为event handler

我们需要不断的接收event然后处理event，因此我们需要一个循环（用while或者for循环都可以），这个循环被称为Event loop

为什么这样一个event loop可以同时处理多个请求呢？

**原因很简单：**对于网络通信服务器来说，处理一个用户请求时大部分时间其实都用在了I/O操作上，像数据库读写、文件读写、网络读写等。当一个请求到来，简单处理之后可能就需要查询数据库等I/O操作，我们知道I/O是非常慢的，当发起I/O后我们大可以不用等待该I/O操作完成就可以继续处理接下来的用户请求

## 事件来源：IO多路复用

## 问题：阻塞式IO

当我们进行IO操作，比如读取文件时，如果文件没有读取完成，那么我们的程序（线程）会被阻塞而暂停执行，这在多线程中不是问题，因为操作系统还可以调度其它线程。

**但是：**在单线程的event loop中是有问题的，原因就在于当我们在event loop中执行阻塞式IO操作时整个线程（event loop）会被暂停运行，这时操作系统将没有其它线程可以调度，因为系统中只有一个event loop在处理用户请求，这样当event loop线程被阻塞暂停运行时所有用户请求都没有办法被处理。你能想象当服务器在处理其它用户请求读取数据库导致你的请求被暂停吗？

## 解决方法：非阻塞式IO

异步IO时，假设调用aio_read函数（具体的异步IO API请参考具体的操作系统平台），也就是异步读取，当我们调用该函数后可以立即返回，并继续其它事情，虽然此时该文件可能还没有被读取，这样就不会阻塞调用线程了。此外，操作系统还会提供其它方法供调用线程来检测IO操作是否完成。

就这样，在操作系统的帮助下IO的阻塞调用问题也解决了

## 更好的方法

为什么我们要使用异步这种难以理解的方式编程呢？

**是因为：**阻塞式编程虽然容易理解但会导致线程被阻塞而暂停运行。

**那么聪明的你一定会问了：**有没有一种方法既能结合同步IO的简单理解又不会因同步调用导致线程被阻塞呢？

**答案是肯定的：**这就是用户态线程（user level thread），也就是大名鼎鼎的协程

# 一文读懂进程、线程、协程

## 什么是进程？

**进程，直观点说：**保存在硬盘上的程序运行以后，会在内存空间里形成一个独立的内存体，这个内存体有自己独立的地址空间，有自己的堆，上级挂靠单位是操作系统。

操作系统会以进程为单位，分配系统资源（CPU时间片、内存等资源），进程是资源分配的最小单位

## 什么是线程？

**线程是程序执行中一个单一的顺序控制流程：**

- 1）是程序执行流的最小单元；
- 2）是处理器调度和分派的基本单位。

### 多线程与多核

**内核线程**（Kernel Thread，KLT）：就是直接由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过操作调度器对线程进行调度，并负责将线程的任务映射到各个处理器上。

一般一个处理核心对应一个内核线程，比如单核处理器对应一个内核线程，双核处理器对应两个内核线程，四核处理器对应四个内核线程。

现在的电脑一般是双核四线程、四核八线程，是采用超线程技术将一个物理处理核心模拟成两个逻辑处理核心，对应两个内核线程，所以在操作系统中看到的CPU数量是实际物理CPU数量的两倍

**超线程技术：**就是利用特殊的硬件指令，把一个物理芯片模拟成两个逻辑处理核心，让单个处理器都能使用线程级并行计算，进而兼容多线程操作系统和软件，减少了CPU的闲置时间，提高的CPU的运行效率。这种超线程技术（如双核四线程）由处理器硬件的决定，同时也需要操作系统的支持才能在计算机中表现出来

程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Lightweight Process，LWP），轻量级进程就是我们通常意义上所讲的线程，也被叫做用户线程。

由于每个轻量级进程都由一个内核线程支持，因此只有先支持内核线程，才能有轻量级进程

### 一对一模型

**对于一对一模型来说：**一个用户线程就唯一地对应一个内核线程（反过来不一定成立，一个内核线程不一定有对应的用户线程）

+ 优点
  + 一个线程因某种原因阻塞时其他线程的执行不受影响
+ 缺点
  + 许多操作系统限制了内核线程的数量，因此一对一模型会使用户线程的数量受到限制
  + 许多操作系统内核线程调度时，上下文切换的开销较大，导致用户线程的执行效率下降

### 多对一模型

多对一模型将多个用户线程映射到一个内核线程上，线程之间的切换由用户态的代码来进行，系统内核感受不到线程的实现方式。用户线程的建立、同步、销毁等都在用户态中完成，不需要内核的介入

+ 优点
  + 多对一模型的线程上下文切换速度要快许多
  + 多对一模型对用户线程的数量几乎无限制
+ 缺点
  + 如果其中一个用户线程阻塞，那么其它所有线程都将无法执行，因为此时内核线程也随之阻塞了
  + 在多处理器系统上，处理器数量的增加对多对一模型的线程性能不会有明显的增加，因为所有的用户线程都映射到一个处理器上了

### 多对多模型

**多对多模型结合了一对一模型和多对一模型的优点：**将多个用户线程映射到多个内核线程上，由线程库负责在可用的可调度实体上调度用户线程。

**这使得线程的上下文切换非常快：**因为它避免了系统调用。但是增加了复杂性和优先级倒置的可能性，以及在用户态调度程序和内核调度程序之间没有广泛（且高昂）协调的次优调度

+ 优点
  + 一个用户线程的阻塞不会导致所有线程的阻塞，因为此时还有别的内核线程被调度来执行；
  + 多对多模型对用户线程的数量没有限制；
  + 在多处理器的操作系统中，多对多模型的线程也能得到一定的性能提升，但提升的幅度不如一对一模型的高

### 线程的生命周期

当线程的数量小于处理器的数量时，线程的并发是真正的并发，不同的线程运行在不同的处理器上。

但当线程的数量大于处理器的数量时，线程的并发会受到一些阻碍，此时并不是真正的并发，因为此时至少有一个处理器会运行多个线程

## 什么是协程？

**协程的特点总结一下就是：**

- 1）线程的切换由操作系统负责调度，协程由用户自己进行调度，因此减少了上下文切换，提高了效率；
- 2）线程的默认Stack大小是1M，而协程更轻量，接近1K。因此可以在相同的内存中开启更多的协程；
- 3）由于在同一个线程上，因此可以避免竞争关系而使用锁；
- 4）适用于被阻塞的，且需要大量并发的场景。但不适用于大量计算的多线程，遇到此种情况，更好实用线程去解决。